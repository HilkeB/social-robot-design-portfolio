{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About this portfolio website","text":"<p>This portfolio website was created for the course 'Social Robot Design' and will be regularly updated with interesting insights and project progress!</p>"},{"location":"#about-me","title":"About me","text":"<p>My name is Hilke, and I am an Interaction Technology Master<sup>1</sup> student at the University of Twente. During my Bachelor Creative Technology<sup>2</sup> I learned how to combine broad knowledge of electrical engineering, computer science, and design to create meaningful and technological solutions to a problem. </p> <p></p> <p>Hello, this is me!</p> <p>During my Bachelor I also joined RoboTeam<sup>3</sup>, one of the student teams of the University of Twente, which creates autonomous football robots. During this year I was responsible for the electronics of the robots, and because of this, it should come as no surprise that I really like working with hardware!</p> <p>The knowledge that I gained during my Bachelor and my student team year are valuable skills that I can use during my master of Interaction Technology. During this master program I mainly follow courses about Human-computer interaction in addition to more technical courses. </p> <ol> <li> <p>https://www.utwente.nl/en/education/master/programmes/interaction-technology/\u00a0\u21a9</p> </li> <li> <p>(https://www.utwente.nl/onderwijs/bachelor/opleidingen/creative-technology/)\u00a0\u21a9</p> </li> <li> <p>https://roboteamtwente.nl/\u00a0\u21a9</p> </li> </ol>"},{"location":"project1/","title":"Week 1","text":"<p>During the first project session of the course 'Social Robot Design' the main challenge is to explore different problem spaces in which the ROSE robot<sup>1</sup> can be utilized. </p>"},{"location":"project1/#brainstorm-and-creation-of-building-blocks","title":"Brainstorm and creation of building blocks","text":"<p>During the brainstorm, my project group<sup>2</sup> and I explored possible use cases for the ROSE robot. This was followed by the identification of several building blocks, which became the overarching themes of utility, healthcare, mental health, and entertainment. Below, the digitalized mind map consisting of the building blocks and problem space exploration can be seen.</p> <p></p> <p>Digitalized version of the created mind map during the problem space exploration and the creation of the building blocks</p>"},{"location":"project1/#functional-breakdown","title":"Functional breakdown","text":"<p>After the exploration of the problem space and the creation of the building block, my group<sup>2</sup> and I all analyzed the outcome of the previous phase and determined interesting possible use cases for ROSE. A total of three interesting combinations and cases were identified. </p> <ul> <li> <p>For the building block of Utility, the idea to utilize ROSE in a cool cell came to mind. This can be a harsh environment, and providing some help via ROSE might be an interesting case. The interactive part of this option still needs to be explored.</p> </li> <li> <p>The building blocks of health care and mental health were combined in the idea to utilize ROSE as an amputation rehabilitation buddy. This would work especially well when a patient recently lost their arm. The idea is that ROSE also loses the functionality of one arm. This allows the patient to navigate the challenging and life-altering experience of losing an arm together with ROSE (who also has some challenges that need to be overcome due to the missing arm). A possible method to test this is by role playing.  </p> </li> <li> <p>The building block of entertainment was also explored by utilizing ROSE in interactive play. By combining open play with technology, social boundaries can be broken, and children might be able to play more freely. This can be tested via a Wizard-of-Oz method, in which there is a physically present ROSE that is controlled by a Wizard.</p> </li> </ul> <p></p> <p>Slide representing the three final cases for ROSE</p> <p>Next week one of these scenarios will be further explored.</p> <ol> <li> <p>(https://heemskerk-innovative.nl/news/new-version-of-robot-rose-tested-at-dutch-care-home)\u00a0\u21a9</p> </li> <li> <p>F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"project2/","title":"Week 2","text":"<p>The aim of this week was to explore and create a story-based design method. Carroll <sup>1</sup> does a great job in describing the relevance and possibilities of scenario-based design, stating that it provides a flexible, reflective, and layered method to explore possible design interactions. In addition, Carroll <sup>1</sup> mentions that by abstracting scenarios, designers are able to find and recognize patterns and generalizations, which in turn help a designer to address further challenges. </p> <p></p> <p>Identified challenges and the appropriate approaches of scenario-based design, by Carroll <sup>1</sup>.</p>"},{"location":"project2/#brainstorm-methods","title":"Brainstorm methods","text":"<p>During the lecture, my group and I <sup>2</sup> explored several user-centric design and research methods provided via the \u2018User Innovation Toolbox\u2019 <sup>3</sup>. This exploration provided us with great insights into the currently available design methods, and after reviewing all of them, we grouped them into categories. During this activity, we identified several categories, such as diary-based methods, physical brainstorming methods, and scenario-based methods.</p> <p></p> <p>Grouped brainstorm techniques using the 'User Innovation Toolbox' <sup>3</sup>.</p>"},{"location":"project2/#story-cubes","title":"Story Cubes","text":"<p>After the initial exploration of brainstorm methods, we discussed which scenario-based brainstorm methods we have used as a group and which ones we found most useful. The concept of story cubes was mentioned often, and because of this, we decided to further investigate the technique. </p> <p>It was found that story cubes urge designers to create stories that are outside their comfort zone. More often than not, a designer tends to create the perfect fitting story in which the product works well and has the intended effect. However, this approach does not allow for the critical exploration of a problem space and the creation of relevant and realistic prototypes. By utilizing story cubes, the designer does not have control over the main story line, and therefore more scenarios can be explored <sup>4</sup>. In addition to this, it was found that story cubes provide a collaborative way of story telling when done in a group. Lastly, it was stated by Bae et al. <sup>5</sup> that the possible shaping and constraining character of story cubes can help to guide the scenarios; it can however also limit the creativity of a designer. </p>"},{"location":"project2/#story-cubes-and-hri","title":"Story Cubes and HRI","text":"<p>Even though story cubes can be considered a generalized brainstorm method, it can also serve as a very relevant brainstorm method in the context of HRI. This is caused by the fact that story cubes can be personalized to fit a certain context. To link the generalized concept of story cubes to HRI, the problem space of the ROSE robot as a co-amputee was further explored during one of the exercises of the lecture. </p> <p></p> <p>Digitalized exploration of ROSE as a co-amputee.</p> <p>During this brainstorm, several building blocks were found that were needed to create a robotic system that could function as a co-amputee. And with these building blocks in mind, several broader themes and applications can be identified: ROSE as mental support and ROSE as coach helping with tasks. This functioned as the basis for the creation of our story cubes.</p>"},{"location":"project2/#dice","title":"Dice","text":"<p>It was decided that a total of three dice would be created as part of our brainstorming method. Above, two main HRI themes have already been identified: ROSE as mental support (encouragement and aid) and ROSE as coach helping with tasks (Application area). These two categories will both receive their own story dice (below a more detailed elaboration on the story cubes can be found). In addition, the lessons and the reflections taught us that positive, negative, and maybe neutral scenarios should be explored when it comes to HRI. Because of this, a third dice was added, which can tell a designer which type of outcome a scenario should have. The scenario-based toolkit will be tested, evaluated, and linked to literature during the case study in week 5</p> <p></p> <p>Online prototype scenario-based tool</p>"},{"location":"project2/#dice-1-application-areas-that-are-linked-to-hri","title":"Dice 1: Application areas that are linked to HRI","text":"<p>Several application areas of HRI were found:</p> <ul> <li>Living alone (task example: Cooking): The utilization of robots that might support physically challenged people at home is widely researched <sup>6</sup>. Even though this might be a future scenario, this is an interesting application for HRI. </li> <li>Home assistance (task example: Cleaning): Supporting users in household tasks is another widely researched application of the field of HRI. By doing this, a higher quality of life might be created <sup>6</sup></li> <li>Skill Training (task example: Gardening): After an amputation, the amputee needs to relearn a lot of skills. This requires a robot that can be used as a tutor to re-learn physical skills; in the paper of Belpaeme et al. <sup>7</sup> this use case was explored and considered promising.</li> <li>Occupational Therapy (task example: Getting clothed): Not only hobbies require skills that need to be relearned after an amputation. A major focus of rehabilitation is relearning how to do basic daily tasks, and robots could be a useful tool for this <sup>8</sup></li> <li>Education (task example: doing hobbies that the patient enjoyed before amputation)</li> <li>Physical rehabilitation (task example: playing sports): The utilization of robots is also being explored in the context of sports <sup>8</sup>. We chose this as a unique category since it extends the physical therapy to a more intense way of movement. </li> </ul>"},{"location":"project2/#dice-2-types-of-encouragement-or-aid","title":"Dice 2: Types of encouragement or aid","text":"<p>Several types of encouragement or aid can be provided by a robot. First, two types of feedback were identified based on the earlier described brainstorm: physical feedback and mental/verbal feedback. </p> <p>Mental/verbal feedback</p> <p>Three types of mental and verbal HRI feedback with respect to an amputee journey are identified:</p> <ul> <li>Emotional feedback: Social robots can provide emotional feedback, which in turn can lead to a positive long-term interaction between the user and the robot <sup>9</sup>. </li> <li>Deciding when to stop: Deciding when to stop might also be a hard thing to do during the recovery period. A social robot might be a valuable feedback system. It was found that people are able to connect with social robots. When this feedback is provided in a human-like manner, suggesting a non-controlling robotic attitude, the robot can have a strong impact <sup>10</sup>.</li> <li>Verbal instructions: As mentioned above, verbal instructions can be of great value in the field of social robotics. It was also found that verbal instructions can improve a learning outcome. This becomes clear in the work of Belpaeme et al. <sup>7</sup>, stating that a robot can provide verbal instructions. These instructions can help a person during hands-on tasks in the natural world <sup>7</sup>.</li> </ul> <p>Physical feedback</p> <p>In addition to verbal feedback, a robot might also provide physical feedback. A total of three different ways were reviewed:</p> <ul> <li>Physical demonstration: Robots, especially humanoid robots, have the possibility to demonstrate physical movements. This could be utilized during rehabilitation sessions at home. A ROSE-like robot is utilized by Beraldo et al. <sup>11</sup> to teach the correct arm movements during physiotherapy. </li> <li>Physical assistance in a task: In addition to just providing a physical demonstration, a robot might also assist a user during a task. This means that the robot and user would have to work together. </li> <li>Emotional body posture: Feedback and encouragement can be provided via speech; however, a lot of our communication is done via body posture, and it was found by Olsson et al. <sup>12</sup> that it is possible to create emotional body postures for social robots.  </li> </ul>"},{"location":"project2/#dice-3-outcome-of-the-scenario","title":"Dice 3: Outcome of the scenario","text":"<p>As earlier mentioned, the lectures and reflective assignments showed us that a designer should also consider negative outcomes and should move away from the \u2018perfect scenario\u2019. Because of this, a die was added with three different outcomes (all three outcomes are mentioned twice on the dice since a die has six sides \ud83d\ude0a) This means that the content of this dice is:</p> <ul> <li>2x Positive outcome: The robot allows for a positive outcome, or the robot allows for the intended outcome of the scenario.</li> <li>2x negative outcome: The robot has a negative outcome on the outcome, or the robot does not provide the intended outcome of the scenario.</li> <li>2x neutral outcome: The Robot does not have a significant effect on the outcome.</li> </ul>"},{"location":"project2/#scenarios-by-group-member-snanwami","title":"Scenarios by group member S.Nanwami","text":"<p>After the creation of our HRI story cubes, all team members were asked to create a story using the dice. Once the activity was completed, all the stories created were reviewed together, and it was found that a broad range of scenarios were created due to the restrictive nature of the dices. Below, two examples of the scenarios created can be found. I chose to add the scenarios created by S.Nanwami since they showcase two very different outcomes. </p> <p>Gardening + Verbal Instructions + Positive (Regular Scenario)</p> <p>The user tries to plant flowers, which he has never done before. ROSE robot offers verbal instructions on how to plant these plants. i.e., \u201cDig a hole 5 cm wide,\u201d \u201cPlace the pot in the hole,\u201d \u201ccover the pot with soil\u201d... Through this, ROSE provides simple, clear instructions on how to plant the plants properly. This will allow the user to feel satisfied with the result, since the plants will grow properly. Thus, a positive outcome is produced: The robot helps in teaching the user and gains more confidence.</p> <p>Sports + Emotional Stimuli + Neutral (Speculative scenario)</p> <p>While the user is participating in a physical (sport) exercise, the robot is encouraging the user by providing them with emotional stimuli such as \u201cKeep it up!\", \u201cYou are doing great\u201d. With this, the user might realize that they can play with the system and still receive this feedback without completing the task in hand. They could find a way to move the camera or just move in specific moments, such as when ROSE perceives that the user is completing the task. This would basically mean that ROSE will continue providing emotional feedback and encouragement without truly needing to, since the user isn\u2019t completing the task.  This in essence leads to no improvement but not much harm either, so the outcome is Neutral: The technology does not help or negatively impact the physical condition of the user.</p>"},{"location":"project2/#storyboard-of-a-scenario","title":"Storyboard of a scenario","text":"<p>Lastly, I created a storyboard of a scenario generated by R. den Otter.</p> <p></p> <p>Storyboard negative scenario</p> <ol> <li> <p>J. M. Carroll, \u2018Five reasons for scenario-based design\u2019, Interacting with Computers, vol. 13, nr. 1, pp. 43-60, sep. 2000, doi: 10.1016/S0953-5438(00)00023-0.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born\u00a0\u21a9</p> </li> <li> <p>\u2018User Innovation Toolbox\u2019, Pelckmans Uitgevers. Accessed: May 6th  2025. [Online]. Available at: https://www.pelckmansuitgevers.be/user-innovation-toolbox.html\u00a0\u21a9\u21a9</p> </li> <li> <p>F. Weder, S. Lemke, en A. Tungarat, \u2018(Re)storying Sustainability: The Use of Story Cubes in Narrative Inquiries to Understand Individual Perceptions of Sustainability\u2019, Sustainability, vol. 11, nr. 19, p. 5264, sep. 2019, doi: 10.3390/su11195264.\u00a0\u21a9</p> </li> <li> <p>Bae, B.C., Seo, G. and Cheong, Y.G., 2016. Towards procedural game story creation via designing story cubes. In Interactive Storytelling: 9th International Conference on Interactive Digital Storytelling, ICIDS 2016, Los Angeles, CA, USA, November 15\u201318, 2016, Proceedings 9 (pp. 399-402). Springer International Publishing.\u00a0\u21a9</p> </li> <li> <p>S. Bedaf, G. J. Gelderblom, en L. De Witte, \u2018Overview and Categorization of Robots Supporting Independent Living of Elderly People: What Activities Do They Support and How Far Have They Developed\u2019, Assistive Technology, vol. 27, nr. 2, pp. 88-100, apr. 2015, doi: 10.1080/10400435.2014.978916.\u00a0\u21a9\u21a9</p> </li> <li> <p>T. Belpaeme, J. Kennedy, A. Ramachandran, B. Scassellati, en F. Tanaka, \u2018Social robots for education: A review\u2019, Sci. Robot., vol. 3, nr. 21, p. eaat5954, aug. 2018, doi: 10.1126/scirobotics.aat5954.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>I. H. Han e.a., \u2018Human-Robot Interaction and Social Robot: The Emerging Field of Healthcare Robotics and Current and Future Perspectives for Spinal Care\u2019, Neurospine, vol. 21, nr. 3, pp. 868-877, sep. 2024, doi: 10.14245/ns.2448432.216.\u00a0\u21a9\u21a9</p> </li> <li> <p>I. Leite, G. Castellano, A. Pereira, C. Martinho, en A. Paiva, \u2018Empathic Robots for Long-term Interaction: Evaluating Social Presence, Engagement and Perceived Support in Children\u2019, Int J of Soc Robotics, vol. 6, nr. 3, pp. 329-341, aug. 2014, doi: 10.1007/s12369-014-0227-1\u00a0\u21a9</p> </li> <li> <p>Torrey, C., Fussell, S.R. and Kiesler, S., 2013, March. How a robot should give advice. In 2013 8th ACM/IEEE international conference on human-robot interaction (HRI) (pp. 275-282). IEEE.\u00a0\u21a9</p> </li> <li> <p>G. Beraldo, A. Bajrami, A. Umbrico, G. Cortellessa, en M. C. Palpacelli, \u2018AI-Enabled Framework for Augmenting Upper Limb Rehabilitation With a Social Robot\u2019, in 2024 20th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA), Genova, Italy: IEEE, sep. 2024, pp. 1-8. doi: 10.1109/MESA61532.2024.10704845.\u00a0\u21a9</p> </li> <li> <p>E. M\u00e5rell-Olsson e.a., \u2018Navigating the Human\u2013Robot Interface\u2014Exploring Human Interactions and Perceptions with Social and Telepresence Robots\u2019, Applied Sciences, vol. 15, nr. 3, p. 1127, jan. 2025, doi: 10.3390/app15031127.\u00a0\u21a9</p> </li> </ol>"},{"location":"project3/","title":"Week 3","text":"<p>During the week\u2019s lesson, an expressive toolkit was designed to explore the movement of a robot.</p>"},{"location":"project3/#paper-or-plastic-robot-puppeteer-interaction","title":"Paper (or plastic) Robot Puppeteer Interaction","text":"<p>To explore the fact that emotional prototyping does not need expensive robots, materials, or extensive methods, an exercise was done during this week\u2019s class. We used a cup with two squares on it (I drew eyes over them for better visibility).  We tilted the cup up and down in an effort to convey emotions. This was surprisingly effective. When the cup \u2018looked up\u2019 it seemed happy or proud. And all of us were feeling some type of pity, which was expressed via an \u2018aahhhwwww, sad\u2019 when the cup looked down. </p> <p></p> <p>Cup looking sad/ashamed and proud/happy.</p>"},{"location":"project3/#brainstorming","title":"Brainstorming","text":"<p>To find out how we wanted to create the design toolkit, my group <sup>1</sup> and I first had a quick brainstorm on what we could use as a starting point of our motion/movement toolkit. We talked about windy-boys and how they are always happy even though they are forced to live outside (preferably during a storm). Their movements convey enthusiasm when blowing in the wind. However, when a windy boy gets stuck, it also conveys a sense of sadness. We also explored several easy-to-use, non-humanoid robots, such as the Sphero <sup>2</sup> and the Dot robot <sup>3</sup>. Their non-humanoid form might allow us to explore emotions without focusing on the aesthetics of a robot <sup>4</sup>. In addition, the Sphero and Dot are both relatively low-cost and are highly intuitive to use and control. Lastly, we explored the possibility of a more tech-focused approach by utilizing a Kinect to mirror human emotional posture to a robot. This approach is linked to Wizard of Ozzing since it allows a user to easily map human posture to a robot. In the end, my group and I chose the Sphero robot as the basis of our toolkit due to its cost-effectiveness, intuitiveness, and greater freedom. </p> <p></p> <p>Drawing of Windy-man.</p>"},{"location":"project3/#toolkit","title":"Toolkit","text":"<p>After some discussion with the teacher, we also decided to focus on the hallway behavior of social robots in a hospital setting. For this specific case, my group and I decided to focus on how to convey urgency via movement and color. (The toolkit might be applicable for other emotions; however, due to the limited time, urgency was deemed relevant in a hospital setting.) </p> <p>For this toolkit, an emotion can be selected via the valence-arousal grid <sup>5</sup>. This emotion will be linked to a color. After this is done, a level of urgency can be chosen (no urgency, some urgency, high urgency). This will be linked to movement guidelines, which will be described below. </p> <p></p> <p>Valance-Arousal spectrum by Feldman via Wikimedia <sup>5</sup>. </p>"},{"location":"project3/#color","title":"Color","text":"<p>Color can be used to convey emotions, and therefore they also might be interesting to utilize when conveying a sense of urgency.</p> <ul> <li>Green eyes in robots are often associated with positive emotions or attitudes such as friendliness, enjoyment, or joy <sup>6</sup>. </li> <li>Yellow is often perceived as a neutral color. It does not convey a lot of specific emotions, however; it is still perceived as positive or friendly <sup>7</sup>. </li> <li>Blue can be associated with more negative emotions or emotions that are on the low-valance side of the valance spectrum <sup>8</sup>. </li> </ul>"},{"location":"project3/#movement","title":"Movement","text":"<p>Implicit methods such as body movement and motion can be used to convey intent. When a robot has to convey urgency, it can be argued that a minimum of socialness should be conveyed. When reviewing the work of Francis et al. <sup>9</sup> several guidelines to ensure social robot path finding and movement can be found: Safety, Comfort, Legibility, Politeness, Social Competence, Understanding other agents, proactivity, and responding appropriately. To create the movement component of the toolkit, the importance of adhering to these set guidelines will be discussed (with respect to the content of the paper <sup>9</sup>). </p> <p></p> <p>Movement guidelines inspired by the paper of Francis et al. <sup>9</sup>. </p>"},{"location":"project3/#step-by-step-plan-of-toolkit","title":"Step-by-step plan of toolkit","text":"<p>Below a digital representation of the toolkit can be seen. In addition, an example scenario is worked out.</p> <p></p> <p>Toolkit and example scenario.</p>"},{"location":"project3/#video","title":"Video","text":"<p>After the creation of the toolkit, we explored several combinations of emotions and levels of urgency. Unfortunately the colors are not really visible in this video. </p> <p>The expressive toolkit will be tested, evaluated, and linked to literature during the case study in week 5.</p> <ol> <li> <p>F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born\u00a0\u21a9</p> </li> <li> <p>\u2018STEM Kits &amp; Robotics for Kids | Inspire STEM Education with Sphero\u2019. Accessed: May 11th 2025. [Online]. Available at: https://sphero.com\u00a0\u21a9</p> </li> <li> <p>\u2018Robots\u2019, Wonder Workshop. Accessed May 11th 2025. [Online]. Available at: https://www.makewonder.com/en/robots/\u00a0\u21a9</p> </li> <li> <p>G. Hoffman en W. Ju, \u2018Designing Robots With Movement in Mind\u2019, Journal of Human-Robot Interaction, vol. 3, nr. 1, p. 89, mrt. 2014, doi: 10.5898/JHRI.3.1.Hoffman.\u00a0\u21a9</p> </li> <li> <p>http://imagine-it.org/gamessurvey, English:  Psychologist Russell\u2019s model of arousal and valence. 2009. Accessed May 12th. [Online]. Available at: https://commons.wikimedia.org/wiki/File:Valence-Arousal_Circumplex.jpg\u00a0\u21a9\u21a9</p> </li> <li> <p>K. Koike et al., \u201cAcademic Emotions Affected by robot eye Color: An Investigation of Manipulability and Individual-Adaptability,\u201d International Journal of Advanced Computer Science and Applications, vol. 10, no. 4, Jan. 2019, doi: 10.14569/ijacsa.2019.0100450.\u00a0\u21a9</p> </li> <li> <p>\u201cArtificial emotion expression for a robot by dynamic color change,\u201d IEEE Conference Publication | IEEE Xplore, Sep. 01, 2012. https://ieeexplore.ieee.org/abstract/document/6343772\u00a0\u21a9</p> </li> <li> <p>C. Liao and Y. Hsu, \u201cColour\u2010emotion association and colour preference for elder care robot appearance,\u201d Coloration Technology, vol. 139, no. 4, pp. 369\u2013384, Nov. 2022, doi: 10.1111/cote.12653.\u00a0\u21a9</p> </li> <li> <p>A. Francis e.a., \u2018Principles and Guidelines for Evaluating Social Robot Navigation Algorithms\u2019, J. Hum.-Robot Interact., vol. 14, nr. 2, pp. 1-65, jun. 2025, doi: 10.1145/3700599.\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"project4/","title":"Week 4","text":"<p>Warning</p> <p>Due to sickness, I was unable to attend the lecture on Embodiment; because of this, I did not take part in the group work of this week since my group members <sup>1</sup> were able to finish the work during the lecture. </p> <p>My group members designed a toolkit that can help researchers and designers develop a fitting appearance for an interactive robot. The created toolkit consists of three types of building blocks that can be combined to experiment with the embodiment of a robot:</p> <ul> <li>Fundamental blocks: Basis shapes in different shapes and colors can be utilized as the basis of the robot. These fundamental blocks will be fully covered in Velcro to allow a designer to stick another block onto it. </li> <li>Additional props: A unique appearance of the robot, in addition to facial expression, can be achieved by utilizing different types of wooden fruits and vegetables. These wooden foods can be \u2018cut\u2019 since they are held together with Velcro. The wooden food parts can be Velcro-ed onto the fundamental blocks.</li> <li>Technical building blocks: The technical part of a social robot can be added via the technical blocks. My group added these types of blocks to allow for the exploration of the socialness and technical capabilities of a robot. Examples of technical blocks are servo motors, LED screens, LED lights, buttons, speakers, a camera module, two grab claws, and multiple attachable wheels. These technical blocks can be Velcro-ed to the fundamental blocks. </li> </ul> <p>My group chose to make the components modular to allow for the exploration of a wide range of robots and types of embodiments. </p> <p>To provide a bit of guidance during the embodiment exploration, a user is asked to provide some input, which is later mapped to colors, shapes and technical blocks. </p> <ul> <li>First the user is asked if there is a target emotion. When the emotion is positive, a yellow fundamental block in a circular shape is suggested. When the target emotion is neutral, a green fundamental block with a square or rectangular shape is suggested. When the target emotion is negative, a blue triangular fundamental block is suggested. The mapped colors were found in the work of Jonauskaite &amp; Mohr <sup>2</sup> and Kumarasamy et al. <sup>3</sup>. The mapped shapes were found by reviewing the works of Strohmeier et al. <sup>4</sup>,<sup>5</sup></li> <li>After this, the user is asked about the preferred type of feedback. This input is mapped to one, or two relevant and fitting technical building blocks. </li> <li>Lastly, the target group is asked. When the target groups are children, the block sizes will be smaller, and when the target groups consist of adults, larger blocks will be utilized. The embodiment toolkit will be tested, evaluated, and linked to literature during the case study in week 5</li> </ul> <p></p> <p>Designed embodiment toolkit designed by group<sup>1</sup>, drawn by me.</p> <ol> <li> <p>F. den Brok, S. Nanwani, D. Doeleman, R. den Otter\u00a0\u21a9\u21a9</p> </li> <li> <p>D. Jonauskaite and C. Mohr, \u201cDo we feel colours? A systematic review of 128 years of psychological research linking colours and emotions,\u201d Psychonomic Bulletin &amp; Review, Jan. 2025, doi: 10.3758/s13423-024-02615-z.\u00a0\u21a9</p> </li> <li> <p>J. Kumarasamy, P. D. Apayee, and M. Subramaniam, \u201cEmotion and Expression Responses Through Colour: A literature review,\u201d SSRN Electronic Journal, Jan. 2014, doi: 10.2139/ssrn.2435741.\u00a0\u21a9</p> </li> <li> <p>P. Strohmeier, J. P. Carrascal, B. Cheng, M. Meban, and R. Vertegaal, \u201cAn Evaluation of Shape Changes for Conveying Emotions,\u201d Researchgate, May 2016, doi: 10.1145/2858036.2858537.\u00a0\u21a9</p> </li> <li> <p>P. Strohmeier, J. P. Carrascal, B. Cheng, M. Meban, and R. Vertegaal, \u201cAn Evaluation of Shape Changes for Conveying Emotions,\u201d ACM Digital Library, May 2016, doi: 10.1145/2858036.2858537.\u00a0\u21a9</p> </li> </ol>"},{"location":"project5/","title":"Week 5","text":"<p>During this week\u2019s project meeting, a case study was conducted to test the created toolkits. During the past few weeks, the prototypes created have already been tested. However, where possible, a more advanced prototype was created and used during the case study of this week. </p>"},{"location":"project5/#toolkit-1-a-scenario-based-toolkit","title":"Toolkit 1: A scenario-based toolkit","text":"<p>The first toolkit that was created for this course was a scenario based toolkit. </p> <p></p> <p>Online prototype scenario-based tool</p> <p>However, to test the toolkit in a physical and collaborative setting, three physical dice were created by F. den Brok:</p> <p></p> <p>HRI dices prototype</p>"},{"location":"project5/#case-study","title":"Case study","text":"<p>A case study was conducted in Design lab. During this case study, my group and I <sup>2</sup> tested this toolkit by rolling the dice and creating scenarios:</p> <ul> <li>Positive, emotional feedback/talking, arts/hobbies: Misses Johnson knitting in the common room of the care house; her motor skills are not what they used to be, and she made some mistakes. In frustration, she tried to take down her work when ROSE noticed. ROSE asks her: Why did you put it down? You were doing great! We can work it out together. On her screen, she shows a possible fix, and they work it out together. </li> <li>Working together, gardening, negative outcome: Bob and ROSE are working in the garden together. To finish the work faster, Bob provides ROSE with specific tasks, and they split up the work. ROSE goes across the field instead of going to the pavement on the freshly mowed lawn and runs over potatoes starting to grow. Bob gets angry and frustrated. Bob calls ROSE, but ROSE does not receive the message and continues on with her task. Bob is frustrated and disconnects ROSE.</li> </ul> <p>Below, a filled-in POEMS framework can be seen:</p> <p></p> <p>POEMS framework <sup>1</sup> scenario-based toolkit case study <sup>1</sup></p>"},{"location":"project5/#insights-after-testing","title":"Insights after testing","text":"<p>After testing the toolkit, we concluded that the dice are a nice tool to explore scenarios'. They provide some guidance; however, the open-ended character of the dice allows a designer to create out-of-the-box scenarios. Especially the dice about the outcomes of the scenario's allow for a nice exploration. I found it really nice to be forced to also think about possible negative and neutral outcomes of the scenario's. The scenario of ROSE and Bob is a good example of this. As a designer, it reminds me to also think about the possibility of ROSE not hearing or understanding any communication effort. It allows me to rethink what the minimum range of the microphones of the robot are and if a robot should be able to hear everything. This does show that storytelling can take on an important role in a design process, and therefore I do support the quote of Thomas Erickson shared during the lecture of week 2:</p> <p>Quote</p> <p>Design is a distributed social process, and, as a result, communication plays a vital role. <sup>3</sup></p> <p>The link to HRI of the digital is a bit too specific, which leads to less creative freedom. To mitigate this, story cubes with only symbols were created. By doing this, the link to HRI became a bit more implicit instead of explicit; however, it did allow for more conversation. In addition to this, we discussed if the physical story cubes were more beneficial over the digital prototype. We found that the physical story cubes provide a sense of control since you are able to shuffle the order of the dice, and you are able to pass the dice over to another team member. </p>"},{"location":"project5/#toolkit-2-an-expressive-toolkit","title":"Toolkit 2: An expressive toolkit","text":"<p>The expressive toolkit was not iterated upon this week since it was already tested in detail, and it was not possible to gain access to a Sphero robot in time. Below, a video can be found that was recorded during the third week of this course.</p> <p>After a reflective conversation with the entire group, it was still possible to fill in the POEMS framework.</p> <p></p> <p>POEMS framework <sup>1</sup> expressive toolkit case study</p>"},{"location":"project5/#insights-after-discussion","title":"Insights after discussion","text":"<p>During the discussion we as a group had about our expressive toolkit, we discussed the outcome of our test. During the test, a Sphero robot was used, and this was a good choice since the lack of humanized features on the tiny robot ball allowed us to only review the movement and expression without being distracted. The Sphero was, however, a bit hard to control, and the colors of the lights were not really visible. Despite this, the toolkit provided us a good foundation to test the expression of urgency through movement. It was concluded by the group that especially high urgency and a low level of urgency (roaming behavior) were expressible via movement patterns. The level of some urgency was a bit harder to convey, since it relied on a lot of nuances. </p> <p>The toolkit was created based on the guidelines for social robot path finding by Francis et al. <sup>4</sup>. Because of this, it is no surprise that it was possible to recognize certain behaviors of the Sphero robot. </p>"},{"location":"project5/#toolkit-3-an-embodiment-toolkit","title":"Toolkit 3: An embodiment toolkit","text":"<p>After a digital prototype, a paper prototype was created by me to test the embodiment toolkit. Three of the participants were tasked with creating a robot embodiment that suited their wants and needs. The social guidelines (Safety, Comfort, Legibility, Politeness, Social Competence, Understanding other agents, proactivity, and responding appropriately) also have similarities with the work of Cyntia Breazeal on the first social Robot: Kismet <sup>5</sup>. In addition to this, the creation of an expressive toolkit through movement showed resemblance with the work of Laban <sup>6</sup> in which the space, weight, and flow/time of a motion could be used to convey emotions. </p> <p></p> <p>Embodiment prototype</p> <p></p> <p>POEMS framework <sup>1</sup> embodiment toolkit case study</p> <p>The following three robot embodiments were created (from left to right):</p> <ul> <li>The robot should be a positive and approachable robot that finds its way through sonar. To achieve this, two speakers were placed on the fundamental block and represented the eyes of the robot. In addition, a blueberry representing the receiver was added to the robot.</li> <li>The blue color was used to evoke calm and negative, sad emotions since this robot is a robot to talk to when you are sad, and therefore it needs to be empathic and show it feels you. Ears, since it can hear and make sounds (beeps). I also gave it a nose and eyes, since it is a social robot that is made for interaction with humans. The joystick on the head can be used to provide input to the robot and set it to different modes, such as listening, cheering up, waking up, and sleeping. </li> <li>The robot is meant to represent a sort of pet buddy who helps with tasks and guiding around the house choirs. The yellow color is meant to represent a calm and happy robot that I'd always be there to support. The top cone can rotate to help detect where to clean up, the watermelon can tilt up and down to indicate where to go, and the tail in the back (banana) can jiggle to indicate trouble has been found.</li> </ul> <p></p> <p>Results of the embodiment case study</p>"},{"location":"project5/#insights-after-testing_1","title":"Insights after testing","text":"<p>After the testing, we concluded that the color coding of the robot is a bit simplified, since colors can be used for way more than only conveying an emotion. A total of three different and interesting embodiments were created. A bigger variety of fundamental blocks, or moldable fundamental blocks, would provide a more realistic exploration. The velcro allowed for full exploration of the physical body of the robot, and the technical components were varied and allowed for the exploration of functionalities. </p> <p>The combination of fundamental blocks and technical blocks allowed us to explore not only the technical and robotic capabilities of a robot, but also the social aspects of the design. During the reflection of week 4 user-centered design methods were discussed. These methodologies do not only look at what a robot should do, but also how a robot should do things or how a robot should be perceived. By exploring the embodiment of a robot via shapes and fruits, the look and feel of a robot can be altered to match, or purposefully mismatch the intended use of a robot. It also allows a designer to explore the balance between form and function. </p> <ol> <li> <p>\u2018POEMS \u2013 Research Tool - Nova\u2019. Accessed: May 25th 2025. [Online]. Available at: https://novatools.org/poems-research-tool/\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born\u00a0\u21a9</p> </li> <li> <p>Erickson, T. (1996). Design as storytelling. interactions, 3(4), 30-35.http://doi.org/10.1145/234813.234817\u00a0\u21a9</p> </li> <li> <p>A. Francis e.a., \u2018Principles and Guidelines for Evaluating Social Robot Navigation Algorithms\u2019, J. Hum.-Robot Interact., vol. 14, nr. 2, pp. 1-65, jun. 2025, doi: 10.1145/3700599.\u00a0\u21a9</p> </li> <li> <p>C. L. (Cynthia L. Breazeal, \u2018Sociable machines\u202f: expressive social exchange between humans and robots\u2019, Thesis, Massachusetts Institute of Technology, 2000. Geraadpleegd: 3 juli 2025. [Online]. Beschikbaar op: https://dspace.mit.edu/handle/1721.1/9303\u00a0\u21a9</p> </li> <li> <p>\u2018Laban movement analysis\u2019, Wikipedia. September 27th 2024. Accessed May 14th [Online]. Available at: https://en.wikipedia.org/w/index.php?title=Laban_movement_analysis&amp;oldid=1248108012\u00a0\u21a9</p> </li> </ol>"},{"location":"project6/","title":"Week 6","text":"<p>During this week's project session, a behavior toolkit was created by my group and I (F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born). The tool should preferably not rely on a Wizard of Oz. At the beginning of the lecture, we talked about the difference between the behavior- and expressive toolkit. After a brief discussion, we concluded that in our eyes, the expressive toolkit had a stronger focus on non-verbal communication and expressiveness, while behavior is more about the overarching image. Behavior is more than movement and expression; it includes the way you talk, the way you move, the valance of your actions and more. We wanted to incorporate this, and after some more brainstorming we decided that it might be interesting to create different ROSE personality cards. We were inspired by the 16 personality types <sup>16</sup> and the concept of Dungeons and Dragons <sup>17</sup> in which you can shape your own character and narrative. In addition to this, we found that personality can be of huge influence on how people behave themselves <sup>18</sup>. By using personality types, we aim to create a tool that can be utilized to explore the behavior of ROSE in a lot of different settings. In addition, the tool might allow for the customization of care robots to specifically fit patient needs.</p>"},{"location":"project6/#working-of-the-toolkit","title":"Working of the toolkit","text":"<p>The toolkit works as follows: A caregiver or designer can select a personality type for ROSE. When a caregiver chooses the personality type, they can use the patient's history and knowledge about the patient to select a fitting character type. In addition to this, an interaction designer can also explore behavior in different social settings with this tool. The designer can design their own character sheets or use one of our created sheets. </p> <p>The five personalities were based on literature. We acknowledge that personalities are not always so straight forward as presented below; however, for the aim of this course a total of 5 personality types were chosen:</p>"},{"location":"project6/#rose-the-logician","title":"ROSE the logician","text":"<p>ROSE as the logician.</p>"},{"location":"project6/#rose-the-empath","title":"ROSE the empath","text":"<p>ROSE as the empath.</p>"},{"location":"project6/#rose-the-protector","title":"ROSE the protector","text":"<p>ROSE as the protector.</p>"},{"location":"project6/#rose-the-teacher","title":"ROSE the teacher","text":"<p>ROSE as the teacher.</p>"},{"location":"project6/#rose-the-companion","title":"ROSE the companion","text":"<p>ROSE as the companion.</p> <p>The behavioural toolkit will be tested, evaluated and linked to literature during the case study in week 8</p> <ol> <li> <p>https://www.cogniron.org/final/RA3.php  \"COGNIRON - The Cognitive Robot Comp\u00a0\u21a9</p> </li> <li> <p>Schwartz, H. A., Eichstaedt, J. C., Kern, M. L., Dziurzynski, L., Ramones, S. M., Agrawal, M., ... &amp; Ungar, L. H. (2013). Personality, gender, and age in the language of social media: The open-vocabulary approach. PLOS ONE, 8(9), e73791. https://doi.org/10.1371/journal.pone.0073791\u00a0\u21a9</p> </li> <li> <p>Tausczik, Y. R., &amp; Pennebaker, J. W. (2010). Personality and language use in self-narratives. Journal of Research in Personality, 44(4), 463\u2013470. https://doi.org/10.1016/j.jrp.2010.05.003\u00a0\u21a9</p> </li> <li> <p>Yarkoni, T. (2010). Personality in 100,000 words: A large-scale analysis of personality and word use among bloggers. Journal of Research in Personality, 44(3), 363\u2013373. https://doi.org/10.1016/j.jrp.2010.04.001\u00a0\u21a9</p> </li> <li> <p>https://www.cogniron.org/final/RA3.php  \"COGNIRON - The Cognitive Robot Companion\"\u00a0\u21a9</p> </li> <li> <p>= S. Lee, J. Park, en D. Um, \u2018Speech Characteristics as Indicators of Personality Traits\u2019, Applied Sciences, vol. 11, nr. 18, p. 8776, sep. 2021, doi: 10.3390/app11188776.\u00a0\u21a9</p> </li> <li></li> <li> <p>https://www.researchgate.net/publication/286516732_The_Effects_of_Hand_Gestures_on_Psychosocial_Perception_A_Preliminary_Study\u00a0\u21a9</p> </li> <li> <p>A. Guidi, C. Gentili, E. P. Scilingo, en N. Vanello, \u2018Analysis of speech features and personality traits\u2019, Biomedical Signal Processing and Control, vol. 51, pp. 1-7, mei 2019, doi: 10.1016/j.bspc.2019.01.027.\u00a0\u21a9</p> </li> <li> <p>https://dl.acm.org/doi/full/10.1145/3495244  \"Social Momentum: Design and Evaluation of a Framework for Socially Competent Robot Navigation | ACM Transactions on Human-Robot Interaction\"\u00a0\u21a9</p> </li> <li> <p>https://ieeexplore.ieee.org/document/6630743\u00a0\u21a9</p> </li> <li> <p>S. Lee, J. Park, en D. Um, \u2018Speech Characteristics as Indicators of Personality Traits\u2019, Applied Sciences, vol. 11, nr. 18, p. 8776, sep. 2021, doi: 10.3390/app11188776.\u00a0\u21a9</p> </li> <li> <p>https://link.springer.com/article/10.1007/s10639-022-11132-2  \"The dual role of humanoid robots in education: As didactic tools and social actors | Education and Information Technologies\"\u00a0\u21a9</p> </li> <li> <p>https://link.springer.com/article/10.1007/s10639-024-12570-w\u00a0\u21a9</p> </li> <li> <p>https://dl.acm.org/doi/10.1145/3568294.3580075  \"Designing Robotic Movement with Personality | Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction\"\u00a0\u21a9</p> </li> <li> <p>\u2018Personality Types | 16Personalities\u2019[Online]. Available at: https://www.16personalities.com/personality-types, https://www.16personalities.com/personality-types\u00a0\u21a9</p> </li> <li> <p>https://www.dndbeyond.com/\u00a0\u21a9</p> </li> <li> <p>W. Ickes, M. Snyder, en S. Garcia, \u2018Personality Influences on the Choice of Situations\u2019, in Handbook of Personality Psychology, Elsevier, 1997, pp. 165-195. doi: 10.1016/B978-012134645-4/50008-1.\u00a0\u21a9</p> </li> </ol>"},{"location":"project7/","title":"Week 7","text":"<p>During the lesson of this week, an ethical toolkit was created.</p>"},{"location":"project7/#exploration-of-ethical-toolkit","title":"Exploration of Ethical Toolkit","text":"<p>At the beginning of the lesson, several ethical toolkits could be explored. My group and I chose to explore the Envision Cards <sup>1</sup>. It worked as follows: one of the group members picked a random card and read the content out loud. The content of the card could be used to foster ethical discussions. </p> <p>The first card that was picked revolved around the concept of re-appropriating old technology. The card used the cellphone wire network as an example. In this day and age, everyone has a mobile phone, and a landline is often redundant. However, the cellphone wires were repurposed to carry internet towards people's homes. </p> <p>The second card that was picked revolved around the evaluation of user experience and values. We talked about cameras in public places and about the question of whether it would be a problem if there was a person watching all the camera footage. It helped us discuss the fact that there might be a mismatch between the intent of the designer and how the users experience the effects of the problem. In regard to the camera, the intent is to enlarge public safety; however, it might also make people feel watched or cause a privacy breach.</p> <p></p> <p>Envision cards discussed by the group.</p>"},{"location":"project7/#created-ethical-toolkit","title":"Created Ethical Toolkit","text":"<p>During the lesson, my group and I <sup>2</sup> explored the possibility to involve a robot in an ethical discussion. It was suggested that the embodiment of the robot could lead to interesting results and that it might be interesting to utilize a robot with a screen (for example, a Pepper robot) to also show videos. The robot can ask questions about the video and talks from an \"I\" perspective. Below, a storyboard of our ethical toolkit is depicted:</p> <p></p> <p>Ethical toolkit <sup>3</sup>, <sup>4</sup>, <sup>5</sup>, <sup>6</sup>, <sup>7</sup></p> <p>In the reflection of this week, the question of whether a robot should be a stakeholder in ethical discussions will be evaluated, and they will be tested, evaluated, and linked to literature during the case study in week 8</p> <ol> <li> <p>\u2018Envisioning Cards\u2019, DECKAHOLIC. Accessed 8th of June, 2025. [Online]. Available at: http://www.deckaholic.com/lib/envisioning-cards\u00a0\u21a9</p> </li> <li> <p>F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born\u00a0\u21a9</p> </li> <li> <p>T. Ye, T. Minato, K. Sakai, H. Sumioka, A. Hamilton, en H. Ishiguro, \u2018Human-like interactions prompt people to take a robot\u2019s perspective\u2019, Front. Psychol., vol. 14, p. 1190620, okt. 2023, doi: 10.3389/fpsyg.2023.1190620.\u00a0\u21a9</p> </li> <li> <p>G. A. Abbo, T. Belpaeme, en M. Spitale, \u2018Concerns and Values in Human-Robot Interactions: A Focus on Social Robotics\u2019, 2025, arXiv. doi: 10.48550/ARXIV.2501.05628.\u00a0\u21a9</p> </li> <li> <p>A. Pipitone, A. Geraci, A. D\u2019Amico, V. Seidita, en A. Chella, \u2018Robot\u2019s Inner Speech Effects on Trust and Anthropomorphic Cues in Human-Robot Cooperation\u2019, 2021, arXiv. doi: 10.48550/ARXIV.2109.09388.\u00a0\u21a9</p> </li> <li> <p>T. Nishio e.a., \u2018The Effects of Physically Embodied Multiple Conversation Robots on the Elderly\u2019, Front. Robot. AI, vol. 8, p. 633045, mrt. 2021, doi: 10.3389/frobt.2021.633045.\u00a0\u21a9</p> </li> <li> <p>S. Costa, A. Brunete, B.-C. Bae, en N. Mavridis, \u2018Emotional Storytelling using Virtual and Robotic Agents\u2019, 2016, arXiv. doi: 10.48550/ARXIV.1607.05327\u00a0\u21a9</p> </li> </ol>"},{"location":"project8/","title":"Week 8","text":"<p>During this week\u2019s project meeting, a case study was conducted to test the created behavior- and ethical toolkits. </p>"},{"location":"project8/#toolkit-4-behavioral-toolkit","title":"Toolkit 4: Behavioral toolkit","text":"<p>During the sixth week of this course, a behavioral toolkit was created by my group and I <sup>1</sup>. To test this toolkit, a total of five character sheets were physicalized by F. den Brok:</p> <p></p> <p>Personality sheets were physicalized by F. den Brok.</p> <p>To test this toolkit, we took inspiration from the theater-style type of exploration as shown during multiple lectures. A total of three group members took part in the role-playing; the other two group members watched and took on the roles of observer and notetaker. The toolkit was tested during the following scenario:</p> <ul> <li>ROSE is a care robot that is being utilized in an elderly care home. In this elderly care home, the patients need personalized care. A caregiver who knows the patients chooses the fitting personality type for ROSE and after this, ROSE is ready to help the patients. </li> </ul> <p>Below, a video of two of the runs can be found. The first patient was a grumpy old man who only wanted to take blue pills. Unfortunately, his pills are not blue. The caregiver selected the protector personality for ROSE since the patient needs clear communication and a firm hand. During the second scenario, ROSE encounters an old lady who is roaming around the halls of the care home. Unsure how to get back to the living room, she accepts the assistance of ROSE who is programmed as an empath.</p> <p>The video above was published with the consent of the people who were filmed. However, to protect their privacy online, the roles POEMS framework below are not specified. This is to ensure that the names of the people visible in the video are not directly linkable to their image. </p> <p></p> <p>POEMS framework <sup>2</sup> behavioral toolkit case study.</p>"},{"location":"project8/#insights-after-testing","title":"Insights after testing","text":"<p>The behavioral toolkit allowed us to explore the influence of different personalities of ROSE. The theater approach, as often mentioned during the lectures, also allowed for fun and open-ended exploration. It was concluded that the customization of ROSE can be helpful to ensure that elderly patients feel safe and receive the care that they need. One thing we did not do during the case study was review the same scenario with different personality types. Currently, we only explored personality types that we deemed to be the best fit to the scenario's. It would have been interesting to see how the scenarios would have played out when ROSE is programmed differently. </p>"},{"location":"project8/#tookit-5-ethical-toolkit","title":"Tookit 5: Ethical toolkit","text":"<p>During the seventh week an ethical toolkit was created by my group and I <sup>1</sup>. This toolkit was also tested on 10-07-2025 in Design Lab. Two of my group members (D. Doeleman and R. Den Otter) prepared the content of the conversation. Just like the behavioral toolkit, this toolkit was also tested via role playing. The two earlier mentioned group members play Pepper who showed videos on his tables. R. Den Otter created a scenario in which Pepper had the role of mediator, while D. Doeleman created a scenario in which Pepper presented himself as a sentient being. </p> <p></p> <p>POEMS framework <sup>2</sup> ethical toolkit case study.</p>"},{"location":"project8/#insights-after-testing_1","title":"Insights after testing","text":"<p>This toolkit provided a really fun and interesting conversation. A clear difference was found between Pepper as a mediator and Pepper presented as a sentient being. During the round in which Pepper functioned more as a mediator, the benefit of using Pepper was the novelty and the utilization of the screen of Pepper. However, during the round in which Pepper functioned as a sentient being, slightly more interesting results were found. When Pepper asked personal questions such as: 'Do I have the right to privacy?', 'Why can people just beat me up?' and 'Am I just a tool for you guys?' the group had a hard time answering these questions. The group felt a sense of compassion and sometimes awkwardness, not sure how to express their belief that Pepper is a mere machine instead of a sentient being.</p> <p>The exploration of Pepper as a sentient being provided an ethical enrichment. The almost absurdity of discussion ethics with a machine pretending to have feelings and also believing it helped to explore the awkwardness of robot ethics. In addition to this, it showed themes from different perspectives. Themes such as sustainability ('Will you just throw me away after I am broken?'), robots in health care ('Do you think I am capable of providing emotional support to someone?)? Can I cry with them? Be happy for them?') Or societal issues (Why do you use my body to harm others?) can be meaningfully explored in an out-of-the-box way!</p> <p>The utilization of Pepper as a sentient being reminded me of the cases of robot anthropomorphism that were discussed during the lectures. I already elaborated upon this during the reflection which I added during week 7. The uneasiness with robot mishandling, which was identified by Anthis et al. <sup>3</sup> could be clearly seen during this case study. The presentation of Pepper as a sentient being and the reaction of the people partaking in the discussion were also not fully unexpected. Earlier in this course we discussed the emotional bond between people and their robotic pet <sup>4</sup>. People are able to create strong bonds with robots (reminds me of the movie HER on which I reflected in the reflection of week 1) and the exploration of this bond in combination with ethics proved to be successful!</p> <ol> <li> <p>F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born\u00a0\u21a9\u21a9</p> </li> <li> <p>\u2018POEMS \u2013 Research Tool - Nova\u2019. Accessed: May 25th 2025. [Online]. Available at: https://novatools.org/poems-research-tool/\u00a0\u21a9\u21a9</p> </li> <li> <p>J. R. Anthis, J. V. T. Pauketat, A. Ladak, en A. Manoli, \u2018Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey\u2019, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, Yokohama Japan: ACM, apr. 2025, pp. 1-22. doi: 10.1145/3706598.3713329.\u00a0\u21a9</p> </li> <li> <p>\u2018Beloved Robot Dogs Honored in Funeral Cerenomy, National Georgraphic, YouTube\u2019. Accessed: June 9th 2025. [Online]. Available at: https://www.youtube.com/watch?v=85737zfBWXw\u00a0\u21a9</p> </li> </ol>"},{"location":"project_template/","title":"Project template","text":"<p>I'm still working on this week... see you in the future!</p>"},{"location":"reflection1/","title":"Week 1","text":""},{"location":"reflection1/#how-is-design-research-linked-to-hri","title":"How is design research linked to HRI?","text":"<p>Several pointers to a design research approach with respect to social robots are given. First, the concept of anthropomorphy, or the modelling of machines as human beings, was discussed. According to the authors of this chapter<sup>1</sup>, the rise and accessibility in open source robot hardware has allowed a lot of people to create robotic systems in which human artifacts can be recognized. These human artifacts are linked to the human ability to find a face or a human capacity for communication in an object, animal or, in this case, social robot. These human artifacts lead me to the second pointer. An understanding of these human artifacts in social robots is needed.</p> <p>Another pointer which I found while reading Chapter 8 was the impact of the open source community on the research field of social robotics. Allowing open source experimentation can provide large amounts of prototypes, interactions, robots, and research. An example mentioned by the authors of Chapter 8 is the Arduino company. This company provides open source hardware which can be used to create all kinds of systems.</p> <p>Lastly, some interesting considerations are provided with respect to the design of social robots.</p> <ul> <li>The system should be intuitive and easy to use. This entails that simple interfaces are preferred which allow non expert users to also interact with the system.</li> <li>The face and facial expression of a robot are important. These two aspects are important since communication is done verbally but also non-verbally. To create the most intuitive social behavior, human artifacts should be mimicked. </li> <li>It is important to design a social system in such a way that a user does not experience uncanny valley. This is a phenomenon in which the user feels uneasy due to the high, yet imperfect, human resemblance of a robot. </li> </ul> <p></p> <p>The uncanny valley of personalization, from Mac Reddin<sup>2</sup></p>"},{"location":"reflection1/#digital-vs-embodiment","title":"Digital vs. Embodiment","text":"<p>The author of Chapter 9<sup>1</sup> introduces the idea of a mobile phone as an emotionalized personal robot. By collocating with its user via haptic properties such as gaze and vibration, a mobile phone can stimulate actions or create emotions. In addition to this, the mobile phone is a highly personalized and adaptable device which allows a user to shape the content in a unique way. In addition to this, the author mentioned that the user of a mobile phone can explore their (emotional) self without needing to communicate with others. This highly intimate relationship can also be seen through all the personal messages stored on the phone, photos, and favorite apps.  All the content on a phone can be seen as a representation of emotional memories and according to the author of chapter 9 emotions can be educed by only looking at your mobile phone. </p> <p>All of this means that the combination of a human and the mobile phone can create a social robot. This means that physical form is not the most important property, but the emotional combination of highly personalized content and a device which holds it all. By doing this, a personalized social robot is created which can be used to feel connected, seek emotional contact and as a self exploration device.</p>"},{"location":"reflection1/#her","title":"HER","text":"<p>Unfortunately, I was unable to watch the entire movie, however after watching a ten minute summary created by the YouTube Channel Best Recapped<sup>3</sup>. I think that I have a good enough understanding to answer this question.</p> <p>After watching the summary of her some similarities can be found with the mobile phone: both Samantha (the operating system) and a mobile phone hold a lot of emotional information and are both capable of inflicting emotions. However, there is one key difference. During the film \u2018Her\u2019 the operating system is approached as a human entity or an entity on its own. This can hardly be said about the mobile phone, which is still seen as a utility. This means that there also is a shift from a co-combination of a human agent and a mobile device to an operating system as a social robot.</p> <p>This leads to the question of whether Samantha can be considered a social robot, or if the system is a highly social agent? Even though Samantha can communicate via a screen, the screen is merely used as a communication channel. It is not a part of Samantha making Samantha a social agent. This would mean that embodiment (The mobile phone) does in fact matter.</p> <p>The summary also made me think back of the end of Chapter 8<sup>1</sup> in which the author explored the possible future relationship between technology and humans. The question of \u2018where does a social robot end and where does the human being begin?\u2019 was asked and I think that this is a highly relevant question which can be reflected upon via the movie \u2018Her\u2019. In this movie the main character Theodore enters a relationship with Samantha, the operating system. It shows the possibility of a future in which, by blurring the line between human and technology, even love can be fully tailored to your needs and wishes without the need to take another person into account. </p>"},{"location":"reflection1/#robot-revolution","title":"Robot revolution","text":"<p>When looking at the over overview of \u2018The coming robot revolution\u2019<sup>4</sup>, the following bullet points are found:</p> <p></p> <p>Overview of 'The coming robot revolution' by Bar-Cohen et al.<sup>4</sup></p> <p>A revolution of robot capabilities is expected due to the rise in computational power and possible nightmare scenarios are predicted. </p> <p>When reflecting on if, and how, the real world deviates from the predictions made, some deviations can be seen. First, even though technology is more intertwined with our personal lives than ever, no truly disastrous technology takeovers have happened (yet). However, humans have become more dependent on technology, a fear mentioned by Vincent. This can be seen in our social relationships with other (social media), the way in which we review digital and analog information and how much tasks we let technology take over. </p> <p>This is all caused by the rapid advancements in computer hardware, something which was also predicted by Bar-Cohen et al. However, at the time of me writing (Spring 2025) the true future of technology remains unclear. </p>"},{"location":"reflection1/#dinosaur-hotel","title":"Dinosaur hotel","text":"<p>When reviewing the case of the robot hotel a lack of adaptability of the robots used can be seen. A lot of different, highly specialized robots were utilized for specific tasks. This means that robots were not flexible and due to the rise in technological advancements, a mismatch between the mental map of the guests and the true capabilities of the robots was created. </p> <p>The CitizenM hotel provides a streamlined and automated experience with more generalized technology (application on mobile phone). This means that the guests have some autonomy over the semi transparent process, something which was missing for the robot hotel. </p> <p></p> <p>Dinosaur check-in at the Henn-Na hotel, from The Greta Escape<sup>5</sup></p>"},{"location":"reflection1/#nabaztag","title":"Nabaztag","text":"<p>The Nabaztag is an expressive design, it is cute, it can move its ears, and emotions can be portrayed via the changeable LED light. Because of this, some form of communication can be done via this robot, in this case communication is linked to limited online stimuli (email, news and weather). </p> <p>The robot does deviate from the definitions of social robots since it lacks autonomy and is unable to show expressive emotions. Because of the limited functionality (It could only display weather, email, and news) combined with shallow emotions the product did not satisfy its users. </p> <p></p> <p>The Nabaztag Rabbit from CEATEC 2008 trade show, from Pink Tentacle<sup>6</sup></p>"},{"location":"reflection1/#cuddlebits","title":"Cuddlebits","text":"<p>Note</p> <p>Unfortunately, it was not possible to find a copy of the paper which was not behind a paywall. The publicly available abstract did not provide me with enough information to answer the question.</p> <p>In summary, a Do It Yourself 1 degree of freedom robot was created. It was found that this robot can be utilized to express affect. Its low-cost fabrication allows for rapid prototyping, and it provided valuable insights on how simple behavior might be used in more complex robots.  </p> <ol> <li> <p>Vincent, J., Taipale, S., Sapio, B., Lugano, G., &amp; Fortunati, L. (Eds.). (2015). Social robots from a human perspective, Springer. doi:10.1007/978-3-319-15672-9\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Mac Reddin - https://www.linkedin.com/pulse/uncanny-valley-personalization-mac-reddin-/\u00a0\u21a9</p> </li> <li> <p>Her 2013 | Movie story recap by Best Recapped - https://www.youtube.com/watch?v=PTozHsOdUug\u00a0\u21a9</p> </li> <li> <p>Bar-Cohen, Y., Hanson, D., &amp; Marom, A. (2009). The coming robot revolution : Expectations and fears about emerging intelligent, humanlike machines. New York: Springer.\u00a0\u21a9\u21a9</p> </li> <li> <p>Giappone: citt\u00e0 tecnologiche all\u2019avanguardia e paesi immersi nella natura - https://www.thegretaescape.com/blog/giappone-citta-tecnologiche-allavanguardia/\u00a0\u21a9</p> </li> <li> <p>Photos from Robots at CEATEC 2008 - https://pinktentacle.com/tag/fujitsu/\u00a0\u21a9</p> </li> </ol>"},{"location":"reflection2/","title":"Week 2","text":""},{"location":"reflection2/#recipe-for-sci-fi-prototyping","title":"Recipe for sci-fi prototyping","text":"<p>Scenario based design can be considered a user-centered design approach which is often utilized early in the development process. The technique relies on the creation of stories and scenarios to explore possible interactions between users and technology<sup>1</sup>. On the Stanford website<sup>2</sup> a scenario-based framework by Rosson and Corroll can be found in which the workflow of the framework is described. First the problem space is analyzed during which the designers should analyze the stakeholders and claims about the current practices. After this, Different scenarios can be created in which people using technology play a central role in the analysis of how the technology could possibly reshape the user\u2019s activity. </p> <p>When reviewing the approach of Johnson for sci-fi prototyping as described on the provided Wikipedia page<sup>3</sup> some major difference can be found. First, the approach of Johnson allows for the exploration and creation of a lot of different futures. In contrast to the user-centered design approach as mentioned above, the workflow of Johnson does not focus on only products. In addition to this, the work of Johnson loosens the need to first investigate the problem space by allowing the designed to pick their own science and to build their own world. This would suggest that the recipe of Johnson is less grounded in the real world, however, by identifying scientific inflections points a scientific grounding is created. Lastly, the process of Johnson encourages reflection on the products, process or societal developments. This is in stark contrast to the scenario-based framework in which the usability and possible specifications are explored. </p>"},{"location":"reflection2/#21st-century-robot-project","title":"21<sup>st</sup> century robot project","text":"<p>Quote</p> <p>\u201c21st Century Robot Manifesto - A Robot Is: Imagined first. Easy to build. Completely open source. Fiercely social. Intentionally iterative. Filled with humanity and dreams. Thinking for her/him/itself.\u201d</p> <p>When reviewing the manifesto as described on the website of the 21st Century robot project<sup>4</sup>, initiated by Johnson, an emphasis on the social, opensource, iterative and almost human-like features can be identified. This focus leads to a humanoid, social robot design with a high acceptance rate in mind and therefore, a similar design to the NAO robot can be seen. This NAO robot is developed by ALDEBARN<sup>5</sup> with the aim of naturally interacting with humans. </p> <p>The story could have evolved differently when the main focus of the robot had shifted from social and human-like to a more functional utilization. This would make the need for a socially approachable robot inferior to a more functional, or function specific robot resulting in a totally different design.</p> <p></p> <p>The NAO robot performing breakdance, from S.R.Europe on WikiMedia<sup>6</sup></p>"},{"location":"reflection2/#consumer-stories","title":"Consumer stories","text":"<p>During the lecture several videos were shown in which robots successfully completed tasks, danced and showed great emotional understanding. This image is common and showcases the evolution of the field of robotics and human machine interaction. </p> <p>However, some caution is needed. The videos, stories and images show approachable robots, functional robots and (emotional) intelligent robots, which can lead to a distorted view on the capabilities and nature of the field of robotics. A great example of this is the YouTube video shown during the lecture in which a robot is asked to sort and put away different items. The task is completed in an impressively humanlike manner, showcasing the great advancements of robots and AI. However, the viewer does not know if the AI was trained for this specific task, how many takes it takes to get it right and if the context specific showcased functionality is the only one of the functionalities or the maximum capability of the AI. </p>"},{"location":"reflection2/#importance-of-storytelling-in-hri","title":"Importance of storytelling in HRI","text":"<p>Storytelling can be a great tool during the design process of a social robot since story telling can influence users, inspire innovation and create expectations. These different outcomes can be achieved by utilizing different aspects of story telling.</p> <p>First, the end results of the story created matters. As already seen in earlier sections, stories can shape the way we think about robots. If only the best possible outcome is chosen, unrealistic expectations might be created with regards to the capabilities of a robot. Secondly, by focusing on the \u2018Why\u2019 aspect of a story the needs of the user, the importance of the innovation and the unique selling point of a technology can be conveyed. Lastly, story telling in the field of HRI can be utilized to ensure transparent and understandable science and design. </p> <p>When looking at the question of whether uncanny valley can be seen as linked to (a) story one of the above mentioned aspects comes to mind. Expectations: A mismatch between expectations and reality of the story can be identified. A robot is portrayed as human-like, however, as a viewer it becomes clear that something is off, and a sense of uneasiness makes it appearance.  </p> <p></p> <p>Uncanny valley diagram, from Smurrayinchester on WikiMedia<sup>7</sup></p>"},{"location":"reflection2/#evidence-base-work-vs-robot-stories","title":"Evidence base work vs robot stories","text":"<p>All of the reflective work as described above funnels down to one theme: evidence versus stories. At this point in time, a balance should be created between the true capabilities of robotic systems and the objective, evidence based capabilities. Even though carefully manufactured stories about social robots almost capable of integrating in human society may be longed after, a realistic, honest and transparent robotics case has yet to be presented.  </p> <ol> <li> <p>C. Stiles-Shields, \u2018Scenario Based Design\u2019, in Encyclopedia of Behavioral Medicine, M. Gellman and J. R. Turner, Red., New York, NY: Springer, 2017, pp. 1-4. doi: 10.1007/978-1-4614-6439-6_101954-1.\u00a0\u21a9</p> </li> <li> <p>\u2018Scenario-based design overview\u2019. Accessed: May 6th 2025. [Online]. Available at: https://web.archive.org/web/20180621145854/http:/ldt.stanford.edu/~gimiller/Scenario-Based/scenarioIndex2.htm\u00a0\u21a9</p> </li> <li> <p>\u2018Science fiction prototyping\u2019, Wikipedia. 6 september 2024. Accessed: May 6th 2025. [Online]. Availabe at: https://en.wikipedia.org/w/index.php?title=Science_fiction_prototyping&amp;oldid=1244336908\u00a0\u21a9</p> </li> <li> <p>\u201821st Century Robot | History\u2019, 21st-century-robot. Accessed: May 6th 2025. [Online]. Available at: https://www.21stcenturyrobot.com/history\u00a0\u21a9</p> </li> <li> <p>\u2018Aldebaran - Nao6\u2019, Aldebaran. Accessed: May 6th 2025. [Online]. Available at: https://aldebaran.com/en/nao6/\u00a0\u21a9</p> </li> <li> <p>S. R. Europe, Fran\u00e7ais :  NAO Robot. 2016. Accessed: May 6th  2025. [Online]. Available at: https://commons.wikimedia.org/wiki/File:NAO_Robot_.jpg\u00a0\u21a9</p> </li> <li> <p>Smurrayinchester, An SVG version of Image:Moriuncannyvalley.gif. 2007. Accessed: May 6th  2025. [Online]. Available at: https://commons.wikimedia.org/wiki/File:Mori_Uncanny_Valley.svg\u00a0\u21a9</p> </li> </ol>"},{"location":"reflection3/","title":"Week 3","text":""},{"location":"reflection3/#design-rules-for-motion","title":"Design rules for motion","text":"<p>In the paper \u2018Designing Robots With Movement in Mind\u2019 by Hoffman &amp; Ju <sup>1</sup>, an expressive movement centered approach is explored in the context of robot design. According to Hoffman &amp; Ju, the main focus of the design process should be on the quality and properties of movements. This means that the aesthetics of the robot is secondary to the motion. By focusing on movement, the internal state, personality, intention and mood of a robot can be conveyed.</p> <p>The authors of the paper also encouraged the design of non-humanoid robots. This is due to the fact that if motion and movement is designed well, a designer does not have to focus on other expressive commodities: the well designed movement is enough. In addition, a designer has more freedom of exploration when they are not constrained by the human-form and therefore it leads to open-ended design possibilities. It also might help to reduce costs, a robot with less degrees of freedom is cheaper to produce and allows for more rapid prototyping. Lastly, a non-humanoid robot might lead to more acceptance. According to Hoffman &amp; Ju, a more abstract robot allows for the user\u2019s imagination without being constrained to pre-learned judgements.  </p> <p>To create well designed motion, the authors explored four design challenges or steps: discovery, implementation, appearance-matching and validation.</p> <ul> <li>Discovery: The right movements and motions for a robot should be explored or discovered. Collaboration with actors, dancers or animators might allow for valuable insight. In addition, prototype techniques such as Wizard of Ozzing or other participatory methods are most suitable for this step.</li> <li>Implementation: A mechanical system which allows for the discovered movements should be designed. The expressive movement of the robot is most important for this stage and because of this, Degrees of Freedom should be explored to allow for smooth and organic movements.</li> <li>Matching form to movement: After the movement is defined, the form of the robot should be created in such a way that it supports the intended movements. The form of the robot can be explored via rapid prototypes tools or via the creation of physical mock-ups.</li> <li>Validation: The robot should be evaluated on its purpose: does the robot achieve the envisioned purpose? </li> </ul> <p>This paper is highly relevant to our project work for this week for which we created a toolkit to explore the expression of a robot through movement and color. By focusing on non-verbal communication via a non-humanoid robot, we were able to explore the conveyed urgency of a robot. </p>"},{"location":"reflection3/#downsides-and-alternatives-of-designing-robot-communication","title":"Downsides and alternatives of designing robot communication","text":"<p>As explored in the previous reflective question it can be concluded that designing robot movement and communication can be seen as a valuable tool. It helps design in a goal oriented way and reduces the time to develop social robotic systems.</p> <p>Despite these positive attributes, some downside of designing robot communication can also be identified. First, a strictly designed robot communication can hinder the creativity of the designer and user. If robot communication is only designed via a framework or design strategy, there is little room for creative exploration. Communication is creative, non-standard and highly personal. An interesting example of exploring beyond the established human-robot communication methodology is the work of Chang et al. <sup>2</sup> in which Olfactory stimuli were explored. It was found that these stimuli can create a bigger perceived friendliness.</p> <p>Another form of exploration beyond the established guidelines and techniques is theater. During the lecture and on the Wiki <sup>3</sup> several examples were provided in which aspects of robot communication (body language, tone of voice etc.) were explored by actors. This method allows for creative, fast and iterative exploration,</p>"},{"location":"reflection3/#hhi-as-a-starting-point-for-designing-hri","title":"HHI as a starting point for designing HRI","text":"<p>Human-Human Interaction (HHI) can be a valuable starting point when designing Human-Robot Interaction since it allows humans to easily recognize the communication styles when applied to robots. However, the extent in which HHI is mapped to HRI is an important factor to consider. The work of Knight and Simmons <sup>4</sup> explored the effectiveness of the Laban movement analysis on social robot communication. </p> <p>The Laban movement analysis <sup>5</sup> is a framework in which human movement is described in the categories of Body (which parts of the body are moving?), Effort (how heavy or light does a movement feel?), Shape (how does the body move and change form?) and Space (How does the movement relate to the environment?). The work of Knight and Simmons <sup>4</sup> explores the expression of emotions in robots with a limited set of degrees of freedom. This means that robots were used which are not fully like humans and have less movement possibilities. It was found that by applying the Laban movement principles to these robots did results in readable expressiveness. </p> <p>This shows that HHI can be considered a valuable starting point for HRI, however some freedom is still allowed. A robot does not have to be a full humanoid copy. However, by following universal human movement patterns, a solid foundation is ensured. </p>"},{"location":"reflection3/#labans-work-on-characterizing-emotion-applied-to-sound-and-other-modalities","title":"Laban\u2019s work on characterizing emotion applied to sound and other modalities","text":"<p>Sound can function as a communication method. In the work of Francoise et al. <sup>6</sup> the Laban movement analysis is applied to create movement through sound. For this research the Effort factors of Effort Weight and Time, as described by Laban <sup>5</sup> were used. It was found that the participants (dances) felt connected to the sound, one participant stated that they were trying to figure out how to mimic the sound and that they felt that their body had the vocabulary to do it. A meaningful link between movement and sound base don the Laban movement can be seen during the research.</p> <p>When reflecting on which aspects of sound can be applied to Labans\u2019 movement framework the Effort factors (Space, weight, Time, Flow) can, in my opinion, be meaningfully mapped:</p> <ul> <li>Space-&gt; How does the movement relate to the environment? The relative direction of space of a sound can be represented by the sharpness and volume of a sound. </li> <li>Weight-&gt; Is the movement light or heavy? This can be mapped to the pitch and loudness of a sound. A light movement can be represented by a high pitched soft sound while a heavy movement might be represented by a low and low sound.</li> <li>Flow and Time-&gt; What is the flow of a movement? Is the movement sudden or slow or sustained?  This can be also represented via sound by for example adding glissando\u2019s (I would interpret this as a flowing and possibly sustained movement) or by playing staccato notes (I would interpret this as controlled, sharp and fast movements). </li> </ul> <p>Other modalities on which Laban\u2019s work might be meaningfully applied are color and color transitions. Is the color perceived as warm or cold, round or sharp? How is the color transition: fast, sudden, isolated? Which colors are combined, are they harmonious, do they clash?</p>"},{"location":"reflection3/#designing-anti-social-behavior","title":"Designing anti-social behavior.","text":"<p>During the project session of this week the work of Franscis et al. <sup>7</sup> on social robot path finding was explored. Several guidelines for nonverbal social robot behavior were found: Safety, Comfort, Legibility, Politeness, Social Competence, understanding other agents, proactivity and responding appropriately. When a robot adheres to these guidelines, social behavior is often achieved. This does also mean that anti social behavior can be designed by breaking these guidelines. Examples of antisocial behavior which can be achieved by breaking these guidelines are sudden and non-fluent movements, entering the personal zone of a user, non-polite behavior or uncontrolled behavior. </p> <p>There is however a difference between the absence of social behavior and designed anti social behavior. The absence of social behavior could be interpreted as a shy, or a socially disadvantaged robot. However, when a robot is designed with anti social behavior in mind, the intent is different since a robot purposefully engages in anti social behavior.</p> <ol> <li> <p>G. Hoffman en W. Ju, \u2018Designing Robots With Movement in Mind\u2019, Journal of Human-Robot Interaction, vol. 3, nr. 1, p. 89, mrt. 2014, doi: 10.5898/JHRI.3.1.Hoffman.\u00a0\u21a9</p> </li> <li> <p>F. Chang e.a., \u2018Crossmodal Interactions in Human-Robot Communication: Exploring the Influences of Scent and Voice Congruence on User Perceptions of Social Robots\u2019, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, Yokohama Japan: ACM, apr. 2025, pp. 1-15. doi: 10.1145/3706598.3713825.\u00a0\u21a9</p> </li> <li> <p>\u2018education:socialrobotdesign:03_expression [Electronic Thingies for Fun Stuff]\u2019. Accessed: May 12th  [Online]. Available at: https://wiki.edwindertien.nl/doku.php?id=education:socialrobotdesign:03_expression\u00a0\u21a9</p> </li> <li> <p>H. Knight en R. Simmons, \u2018Laban head-motions convey robot state: A call for robot body language\u2019, in 2016 IEEE International Conference on Robotics and Automation (ICRA), Stockholm, Sweden: IEEE, mei 2016, pp. 2881-2888. doi: 10.1109/ICRA.2016.7487451.\u00a0\u21a9\u21a9</p> </li> <li> <p>\u2018Laban movement analysis\u2019, Wikipedia. September 27th 2024. Accessed May 14th [Online]. Available at: https://en.wikipedia.org/w/index.php?title=Laban_movement_analysis&amp;oldid=1248108012\u00a0\u21a9\u21a9</p> </li> <li> <p>J. Fran\u00e7oise, S. Fdili Alaoui, T. Schiphorst, en F. Bevilacqua, \u2018Vocalizing dance movement for interactive sonification of laban effort factors\u2019, in Proceedings of the 2014 conference on Designing interactive systems, Vancouver BC Canada: ACM, jun. 2014, pp. 1079-1082. doi: 10.1145/2598510.2598582.\u00a0\u21a9</p> </li> <li> <p>A. Francis e.a., \u2018Principles and Guidelines for Evaluating Social Robot Navigation Algorithms\u2019, J. Hum.-Robot Interact., vol. 14, nr. 2, pp. 1-65, jun. 2025, doi: 10.1145/3700599.\u00a0\u21a9</p> </li> </ol>"},{"location":"reflection4/","title":"Week 4","text":""},{"location":"reflection4/#is-the-discussion-on-embodied-agents-versus-virtual-agents-still-a-relevant-form-can-you-find-other-hybrid-shapes-too","title":"Is the discussion on embodied agents versus virtual agents still a relevant form? Can you find other (hybrid) shapes too?","text":"<p>The discussion on embodied agents versus virtual agents is in my opinion still a relevant discussion due to the rise in virtual agents and social robots. When is something embodied? During a previous reflection, the movie \u2018Her\u2019 [^1] raised the question whether Samantha could be considered a social robot. The fact that it was possible to create a deep connection with an agent without conventional physical presence showed that embodied agents can make the same impact as virtual agents. On the other hand, the movie showed that Semantha was physicalized in some way or form by talking though a screen which could be carried around. </p> <p>This might suggest that there is a gray area when it comes to embodied agents. Is Semantha embodied because there is a screen? Would Semantha be embodied when she talked through a speaker? And if this is the case, would Semantha be even more embodied when the speaker has some googly eyes attached to it, or a possible picture of Semantha? </p> <p>The main question to make a distinction between virtual and embodied agents might be: \u2018Which types of communications are possible with a virtual and an embodied agent?.\u2019 A good example to answer this question is the Furhat <sup>1</sup>, this is a social robot head which has some movement possibilities. A face is projected from the inside of the robot suggesting that the Furhat might be a virtual agent. However, the Furhat is also able to move and therefore can make head gestures and might be able to convey nonverbal emotion through movements when the Laban movement framework <sup>2</sup> is applied (As discussed in the reflection of last week). This allows for more meaningful and embodied interactions, something which cannot be achieved via a strictly virtual agent. </p> <p></p> <p>Furhat, Form Stephen McCarty sources via WikiMedia' <sup>3</sup>.</p>"},{"location":"reflection4/#robotic-capabilities-vs-social-aspects-of-the-design","title":"Robotic capabilities vs social aspects of the design","text":"<p>When a product, or a robot, is designed requirements are created beforehand. These requirements specify what a product should be able to do, what its purpose is, how it should function and what it should achieve. </p> <p>When a product or robot is designed with only robotic capabilities in mind, different requirements will be created. The relevant questions which can be asked for this purpose are:</p> <ul> <li>What should the robot achieve?</li> <li>Which hardware components are needed to create this robot?</li> <li>Are there dimensional restrictions?</li> <li>How do we ensure human safety when working together with the robot?</li> <li>Which software architecture is fitting for our use case?</li> <li>Do we need to take the lifecycle of this robot into account during the design process?</li> </ul> <p>All these questions focus on the capabilities and performance of the robot. After the creation of these requirements, the robot can be developed. This workflow leads to a structured design approach since the requirements are created beforehand via research and client contact. In addition, the requirements can be used to evaluate the robot afterwards. An example of this is the Agile framework <sup>4</sup> in which the client or customer is centralized in the design process. This ensures that the product meets the functional needs and expectations of the client. </p> <p>When a robot is designed with social aspects in mind, the requirements will shift from pure functional requirements to more user centric requirements. This also means that the main focus of the design methods is not the functional needs of a client, but the needs of a customer. These requirements can be created and formulated in the same structured way as the engineering requirements mentioned above. Design methodologies <sup>5</sup> which are user centric are for example User Centered Design, Co-design, Accessibility design or Heuristic Evaluation.</p> <p>These methods shift the focus from the investor/ client to the user and because of this a different set of questions becomes relevant while creating requirements:</p> <ul> <li>How would a robot achieve the task?</li> <li>How should a robot be perceived by the user?</li> <li>How will a user interact with the robot?</li> <li>Which features are needed to achieve the task?</li> <li>How can a robot provide understandable feedback?</li> </ul> <p>These questions differ greatly from the engineering centered questions. However, in practice the two approaches, as described above, should both be used when a social robot is designed. </p>"},{"location":"reflection4/#function-defines-form-vs-social-requirements","title":"Function defines form vs social requirements?","text":"<p>Classical examples of robots with a clear conflict in design aspects that come from function defines and from social requirements are industrial robots which are utilized in a social setting. Often a screen is added to it and some speakers, however these robots were not designed to be interactive and social.</p> <p>A robot which shows a great form fits function is the SPOT robot <sup>6</sup>, this robot is created to walk on rough terrains and due to the design of the robot is doing so very well. It does, however, not always fit the mental picture of people viewing the robot. The robot can be considered cute; however, it is an industrial robot with a lot of power. Since it is not designed or utilized as being cute and interactive, the form does suit the function well.</p> <p>A robot that is designed to be interactive and social and thus has a good balance between form and function is the Paro robot<sup>7</sup>. It is fluffy, it is cute, it is approachable due to its form. In addition, the robot seal can react in a social way by tailoring its responds to the users\u2019 needs. </p> <p></p> <p>Robotic robot seal, by T. museet/Peter H\u00e4ll via Wikimedia commons <sup>8</sup>.</p>"},{"location":"reflection4/#relevant-insights-of-duffy-with-respect-to-our-project-case","title":"Relevant insights of Duffy with respect to our project case","text":"<p>On the website of Edwin Dertien <sup>8</sup> a concise summary of the work by Duffy <sup>9</sup> is provided:</p> <p>Quote</p> <p>He argues for the following guiding principles for building a social robot embodiment: </p> <ul> <li>use social conventions and communication in function and form</li> <li>avoid the uncanny valley</li> <li>use natural (fluent) motion</li> <li>balance function and form</li> <li>balance anthropomorphism and function</li> <li>allow the robot to portray identity</li> <li>make sure artificial emotions do not obstruct interaction <sup>8</sup></li> </ul> <p>The main idea for our case is to utilize the ROSE robot as a co-amputee. The user can re-learn skills and receive emotional support by talking with ROSE and by \u2018going through\u2019 the same struggles. For this case some of the guiding principles are highly relevant. </p> <p>First, it is mentioned by Duffy that a robot should allow for efficient communication and therefore should have its own mechanics to communicate and have social interaction. It is also mentioned that a robot should be able to develop its own identity, this, combined with the transparent communication, allows people to treat the robot as a socially capable entity. This is especially important for our use case of ROSE in which we want to foster a social connection between the amputee and ROSE as co-amputee. </p> <p>This is also strongly linked to the guideline of ensuring that artificial emotions do not obstruct interaction. It is argued by Duffy that the techniques to convey artificial emotions should facilitate social interaction. When ensuring this, the co-amputee might be able to find support via ROSE by having a social connection.</p> <p>The guideline of balancing function and form is always a relevant guideline, however in our case the robot already exists. Despite this, by tuning into the form of ROSE (A robot with only one arm) the function of ROSE as a co-amputee is still balanced.  \u2003</p> <ol> <li> <p>\u2018Furhat Robotics\u2019. Accessed :May 19th 2025. [Online]. Available at: https://www.furhatrobotics.com/\u00a0\u21a9</p> </li> <li> <p>\u2018Laban movement analysis\u2019, Wikipedia. September 27th 2024. Accessed May 14th [Online]. Available at: https://en.wikipedia.org/w/index.php?title=Laban_movement_analysis&amp;oldid=1248108012\u00a0\u21a9</p> </li> <li> <p>RISEConf, English:  10 July 2019; Furhat Robotics Press Conference in the Media Village during day two of RISE 2019 at the Hong Kong Convention and Exhibition Centre in Hong Kong. Photo by Stephen McCarthy/RISE via Sportsfile. 2019. Accessed: May 19th  2025. [Online]. Available via: https://commons.wikimedia.org/wiki/File:RISE_2019_-_44.jpg\u00a0\u21a9</p> </li> <li> <p>\u2018What are Agile frameworks?\u2019, GeeksforGeeks. Accessed: May 19th  2025. [Online]. Available at: https://www.geeksforgeeks.org/what-are-agile-frameworks/\u00a0\u21a9</p> </li> <li> <p>Mao, Ji-Ye, et al. \"User-centered design methods in practice: a survey of the state of the art.\" Proceedings of the 2001 conference of the Centre for Advanced Studies on Collaborative research. 2001.\u00a0\u21a9</p> </li> <li> <p>]\u2018Spot\u2019, Boston Dynamics. Accessed: May 19th 2025. [Online]. Available at: https://bostondynamics.com/products/spot/\u00a0\u21a9</p> </li> <li> <p>\u2018PARO Therapeutic Robot\u2019. Accessed: May 19th 2025. [Online]. Available at: http://www.parorobots.com/\u00a0\u21a9</p> </li> <li> <p>\u2018education:socialrobotdesign:04_embodiment [Electronic Thingies for Fun Stuff]\u2019. Accessed: MAy 18th 2025. [Online]. Available at: https://wiki.edwindertien.nl/doku.php?id=education:socialrobotdesign:04_embodiment\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>B. R. Duffy, \u2018Anthropomorphism and the social robot\u2019, Robotics and Autonomous Systems, vol. 42, nr. 3-4, pp. 177-190, mrt. 2003, doi: 10.1016/S0921-8890(02)00374-3.\u00a0\u21a9</p> </li> </ol>"},{"location":"reflection5/","title":"Week 5","text":""},{"location":"reflection5/#there-is-no-reflection-this-week","title":"There is no reflection this week","text":"<p>No reflection to be seen</p>"},{"location":"reflection6/","title":"Week 6","text":""},{"location":"reflection6/#there-is-no-reflection-this-week","title":"There is no reflection this week","text":"<p>No reflection to be seen</p>"},{"location":"reflection7/","title":"Week 7","text":""},{"location":"reflection7/#are-robots-stakeholders-in-ethical-robotic-questions","title":"Are robots stakeholders in ethical robotic questions?","text":"<p>The field of robotics is larger than ever, and a lot of robotic systems are being implemented into our daily lives. In addition to this, the line between technology and humans is slowly fading away. People easily anthropomorphic robotic systems. A great example of this is the robot funerals held for broken robotic companions <sup>1</sup>. A survey conducted by Anthis et al. <sup>2</sup> showed that the majority of participants thought that torturing robots was morally wrong, and that (sentient) robots should be treated with respect.</p> <p>Despite this, the majority of the research population of the survey of Anthis et al. <sup>2</sup> indicated that they felt uneasy with calling advanced robots\u2019 sentient. In addition to this, the majority indicated to be in favor of a ban on creating future sentient robotic systems. Lastly, most people mentioned that they saw the advancement of robotics as a possible future threat.</p> <p>However, when robotic systems are designed via the three laws of robotics by Asimov <sup>3</sup>, </p> <p>Quote</p> <ul> <li>A robot may not injure a human being or, through inaction, allow a human being to become harmed.</li> <li>A robot must obey the orders given by human beings except where such orders would conflict with the First Law.</li> <li>A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws. <sup>3</sup></li> </ul> <p>The question of whether or not robots should be a stakeholder in ethical debate remains. The wide application of technology in our daily lives would make it a logical choice. As already discussed during the project section of this week, the clear benefit of including robots into the discussion allows for more engagement and enables humans to view questions from different perspectives <sup>4</sup>. The survey of Anthis et al. <sup>2</sup> suggests that there is a perceived ethical way of handling robots. This would make a robot a stakeholder. On the other hand, a robot is not a sentient being and is created for humans. It always has a function and when linked to the three robotic laws of Asimov <sup>3</sup>, there would be no place for robots as stakeholders in ethical discussions.</p>"},{"location":"reflection7/#our-toolkit-and-robots-as-stakeholders","title":"Our toolkit and robots as stakeholders","text":"<p>In our toolkit a robot provides an \u201cI\u201d perspective on the ethical domain. By doing this, the user is enabled to reflect in a different way. By andromorphising the robot, the robot is in someway a stakeholder in the discussion. However, the main goal is to allow for the ethical reflection of humans and therefore the robot is a mere tool in our toolkit. Our toolkit might blur the lines when it comes to robots as stakeholders, which might lead to further questions. Next week the toolkit will be tested and hopefully more insights into this issue will be provided!</p> <p></p> <p>Is a robot a sentient being?</p>"},{"location":"reflection7/#lets-ask-a-robot","title":"Let\u2019s ask a robot!","text":"<p>Out of interest I asked my go to AI system (Duck.ai running GPT 4o) the following question: \u2018Are robots stakeholders in ethical robotic questions? I would like to hear your thoughts on this, as an AI.\u2019 I got the following response: </p> <p>Quote</p> <p>\u2018As an AI, I don't have feelings, emotions, or personal opinions. My responses are based on patterns in data and programmed guidelines. However, I can provide insights based on ethical frameworks and discussions surrounding robotics. The idea of robots as stakeholders raises important questions about responsibility, accountability, and the ethical treatment of technology. While I don't have personal feelings about these issues, I can recognize that they are significant for society as we navigate the integration of advanced technologies into daily life. The focus should remain on ensuring that technology serves humanity positively and ethically.\u2019[5]</p> <p>The response of the AI resonates with the view of Asimov <sup>3</sup> on robotic systems. It centers the human convenience of the technology and dismisses the possibility of robots being stakeholders in the ethical debate.</p> <ol> <li> <p>\u2018Beloved Robot Dogs Honored in Funeral Cerenomy, National Georgraphic, YouTube\u2019. Accessed: June 9th 2025. [Online]. Available at: https://www.youtube.com/watch?v=85737zfBWXw\u00a0\u21a9</p> </li> <li> <p>J. R. Anthis, J. V. T. Pauketat, A. Ladak, en A. Manoli, \u2018Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey\u2019, in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, Yokohama Japan: ACM, apr. 2025, pp. 1-22. doi: 10.1145/3706598.3713329.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>\u2018Laws of robotics\u2019, Wikipedia. 18 februari 2025. Accessed: June 9th 2025. [Online] Available at: https://en.wikipedia.org/w/index.php?title=Laws_of_robotics&amp;oldid=1276408410\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>M. Kropf, \u2018Trust and care robots: philosophical considerations, ethical challenges, and viable options\u2019, Intel Serv Robotics, vol. 18, nr. 2, pp. 339-350, mrt. 2025, doi: 10.1007/s11370-025-00589-y.\u00a0\u21a9</p> </li> <li> <p>Duck.ai running GPT-4o response to the question:  \u2018Are robots stakeholders in ethical robotic questions? I would like to hear your thought on this, as an AI.\u00a0\u21a9</p> </li> </ol>"},{"location":"reflection8/","title":"Week 8","text":""},{"location":"reflection8/#there-is-no-reflection-this-week","title":"There is no reflection this week","text":"<p>No reflection to be seen</p>"}]}