During the lesson of this week an ethical toolkit was created.

## Exploration of Ethical Toolkit
At the beginning of the lesson several ethical toolkit could be explored. My gorup and I chose to explore the Envision Cards [^2]. It worked as follows: one of the groupmembers picked a random card and read the content out loud. The content of the card could be used to foster ethical discussions. 

The first card which was picked revolved around the concept of reappropiriating old technology. The card used the cellphone wire network as an example. In this day and age everyone has a mobile phone nad a landline is often redundant. However, the cellphone wires were repurposed to carry internet towards people their homes. 

The second card which was picked revolved around the evaluation of user experience and values. We talked about camera's in pulic places and about the question if it would be a problem if there was a person wathcing all the camera footage. It helped us discuss the fact that there might be a mismatch between the intent of the designer and how the users experience the effects of the problem. In regards to the camera, the intent is to enlarge public safety, however it might also make people feel watched or cause a privacy breach.

![enivsion cards](images/cards.png)
/// caption
Envisoin cards discussed by the group.
/// 

[^2]: ‘Envisioning Cards’, DECKAHOLIC. Accessed 8th of June, 2025. [Online]. Available at: http://www.deckaholic.com/lib/envisioning-cards

## Created Ethical Toolkit
During the lesson my group and I [^1] explored the possiblility to involvo a robot into an ethical discussion. It was suggested that the emobodiment of the robot could lead to interesting results and that it might be interesting to utilize a robot with a screen (For example a Pepper robot) to also show videos. The robot can ask questions about the video and talks in an I perspective. Below a story board of our ethical toolkit is depicted:

![ethical toolkit](images/storyboard.png)
/// caption
Ethical toolkit [^3], [^4], [^5], [^6], [^7]
/// 

In the [reflection](reflection7.md) of this week, the question if a robot should be a stakeholder in ethical discussions will be evaluated and the will be tested, evaluated and linked to literature during the case study in [week 8](project8.md)

[^1]: F. den Brok, S. Nanwani, D. Doeleman, R. den Otter, H. van den Born
[^3]: T. Ye, T. Minato, K. Sakai, H. Sumioka, A. Hamilton, en H. Ishiguro, ‘Human-like interactions prompt people to take a robot’s perspective’, Front. Psychol., vol. 14, p. 1190620, okt. 2023, doi: 10.3389/fpsyg.2023.1190620.
[^4]:G. A. Abbo, T. Belpaeme, en M. Spitale, ‘Concerns and Values in Human-Robot Interactions: A Focus on Social Robotics’, 2025, arXiv. doi: 10.48550/ARXIV.2501.05628.
[^5]:A. Pipitone, A. Geraci, A. D’Amico, V. Seidita, en A. Chella, ‘Robot’s Inner Speech Effects on Trust and Anthropomorphic Cues in Human-Robot Cooperation’, 2021, arXiv. doi: 10.48550/ARXIV.2109.09388.
[^6]: T. Nishio e.a., ‘The Effects of Physically Embodied Multiple Conversation Robots on the Elderly’, Front. Robot. AI, vol. 8, p. 633045, mrt. 2021, doi: 10.3389/frobt.2021.633045.
[^7]:S. Costa, A. Brunete, B.-C. Bae, en N. Mavridis, ‘Emotional Storytelling using Virtual and Robotic Agents’, 2016, arXiv. doi: 10.48550/ARXIV.1607.05327